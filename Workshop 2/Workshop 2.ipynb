{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e966a0",
   "metadata": {},
   "source": [
    "<center><h1>bogaziciAI Winter Camp</h1></center>\n",
    "<center><h2>Workshop 2</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08048cf",
   "metadata": {},
   "source": [
    "<center><h3>Grading Table</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e13fd43",
   "metadata": {},
   "source": [
    "|             | Part 1 | Part 2      | General Otline      | Total |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| **Points**      | 60          | 30     | 10                  | 100   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083e4b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2eb91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-0.6034323015798435,\n",
       "  0.35078723996566435,\n",
       "  0.8352988265292909,\n",
       "  -0.7098583457975749,\n",
       "  1.0693175756002515),\n",
       " 6.981904457939088)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dataset.pkl\", \"rb\") as file:\n",
    "    points = pickle.load(file)\n",
    "\n",
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d03e66",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "* In this part, you will work with a hypothetical dataset generated by us. The aim is to find the true weights of the input variables that were used to generate this dataset. \n",
    "* You are given a dataset of length 100.000 that consists of 5 features (X) and target (y). For each data point, X is a tuple with 5 features (x1, x2, x3, x4, x5) and y is the target variable.\n",
    "* Write your custom gradient descent algorithm to find the weights. Note that you might want to consider polynomial features too. It is guaranteed that none of the input features are above 2nd degree, so it is enough to only check for the 2nd degree. \n",
    "* After you think that you reached a solution, print the rounded version of the weights so that they only have 1 digit after the comma.\n",
    "* You can refer to below structure while writing your code (You can use your own structure too).\n",
    "* Plot the loss values after each iteration in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3784b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w):\n",
    "    # Our solution is 1 line of code, but don't worry if you deviate\n",
    "\n",
    "def stochastic_dF(w, i):\n",
    "    # Our solution is 2 lines of code, but don't worry if you deviate\n",
    "\n",
    "def stochastic_gradient_descent(loss, stochastic_dF, d, n):\n",
    "    # Our solution is 7 lines of code, but don't worry if you deviate\n",
    "\n",
    "stochastic_gradient_descent(loss, stochastic_dF, d, len(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ddcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "213fdedb",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53af2ef",
   "metadata": {},
   "source": [
    "In this section, you are going to use the dataset given below, and predict the risk of heart attack. <br>\n",
    "https://www.kaggle.com/nareshbhat/health-care-data-set-on-heart-attack-possibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df3cdf",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Split the data into training and test so that you have X_training, X_test, y_training, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe0916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "837e1a3d",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Inspect the data and comment if logistic regression is a good fit to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f05b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "220669b5",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Standardize x with respect to x_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a929a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d893de16",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Apply logistic regression (you can use scikitlearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc4ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa1613c",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Evaluate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03efb39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
